{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìò **How to Use This Template**\n",
    "\n",
    "## **Quick Start Guide**\n",
    "\n",
    "This notebook provides a comprehensive, structured framework for data analysis and predictive modeling following the **PACE methodology** (Plan ‚Üí Analyze ‚Üí Construct ‚Üí Execute).\n",
    "\n",
    "### **Before You Begin:**\n",
    "1. **Save a copy** of this template for your specific project\n",
    "2. **Update the Project Overview** section with your project details\n",
    "3. **Remove sections** that don't apply to your analysis type\n",
    "4. **Add code cells** below each markdown section as you progress\n",
    "\n",
    "### **Workflow by Project Type:**\n",
    "\n",
    "**For Classification Projects** (e.g., churn prediction, fraud detection):\n",
    "- Use all sections including class imbalance handling\n",
    "- Focus on: Logistic Regression, Decision Tree, Random Forest, XGBoost models\n",
    "- Key metrics: AUC-ROC, Precision, Recall, F1-score\n",
    "\n",
    "**For Regression Projects** (e.g., price prediction, forecasting):\n",
    "- Skip class imbalance sections\n",
    "- Focus on: Linear Regression, Decision Tree, Random Forest, XGBoost models\n",
    "- Key metrics: RMSE, MAE, R¬≤, Adjusted R¬≤\n",
    "\n",
    "**For Exploratory/Descriptive Analysis:**\n",
    "- Focus on Plan and Analyze phases\n",
    "- Use statistical testing sections\n",
    "- May skip Construct phase entirely\n",
    "\n",
    "### **Template Navigation Tips:**\n",
    "- üìã Each section has clear objectives and guiding questions\n",
    "- üí≠ Reflection prompts help document decisions and insights\n",
    "- üìä Reference tables provide quick guidance on methods and assumptions\n",
    "- ‚úÖ Use transition checklists to ensure completeness before moving to next phase\n",
    "\n",
    "### **Key Features:**\n",
    "- **Modular Design:** Use only what you need\n",
    "- **Iterative Process:** Revisit earlier sections as needed\n",
    "- **Documentation Built-in:** Insight sections prompt you to record findings\n",
    "- **Best Practices:** Includes guidance on assumptions, ethics, and validation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Project Overview** üìã\n",
    "\n",
    "**Project Title:**  \n",
    "*e.g., Telecom Churn Prediction*\n",
    "\n",
    "**Objective:**  \n",
    "*You are working for a Telecommunications provider. They are losing customers to competitors, but they don't know who is likely to leave. They want you to build a model to predict churn (1 = Customer Leaves, 0 = Customer Stays). The Catch: Most customers are happy. Only a small percentage actually churn. If your model just predicts \"Stays\" for everyone, you'll get high accuracy but provide zero business value.*\n",
    "\n",
    "**Data Source:**  \n",
    "*Synthetic dataset generated internally.*\n",
    "\n",
    "**Key Questions:** \n",
    "\n",
    "* *Are there any missing values, significant outliers or class imbalance that needs to be addressed?*\n",
    "* *Which features are most predictive of customer churn?*\n",
    "* *What is the expected accuracy of the churn prediction model?*\n",
    "\n",
    "\n",
    "**Success Metrics:**  \n",
    "*Recall (How many churners did we catch?) and F1-Score.*\n",
    "\n",
    "*Success Criteria*\n",
    "*Target: Achieve an F1-Score (for Class 1) > 0.70.*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **PACE Methodology** üîÑ\n",
    "\n",
    "This template follows the **PACE** framework for systematic data analysis and modeling:\n",
    "\n",
    "| Stage         | Focus              | Key Activities                                                                 |\n",
    "|---------------|--------------------|-------------------------------------------------------------------------------|\n",
    "| **üìù Plan**   | Define & Prepare   | Business understanding, data exploration, problem formulation                  |\n",
    "| **üîç Analyze**| Explore & Clean    | EDA, data cleaning, feature engineering, statistical analysis                  |\n",
    "| **üîß Construct** | Model & Build   | Feature selection, model development, validation                               |\n",
    "| **üöÄ Execute**| Deploy & Communicate| Model evaluation, insights, recommendations, stakeholder communication         |\n",
    "\n",
    "**PACE Flow:**  \n",
    "*Plan ‚Üí Analyze ‚Üí Construct ‚Üí Execute*\n",
    "\n",
    "*Each stage builds on the previous, ensuring a structured, repeatable approach to data science projects.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **Transition to Plan**\n",
    "Now that you have defined your project overview, move into the planning stage to clarify business context, technical approach, and resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Plan.png\" width=\"75\" height=\"75\" align=left>\n",
    "\n",
    "### **Pace: Plan**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Understand the business scenario and problem**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Key Planning Questions** üí≠\n",
    "\n",
    "**Business Context:**\n",
    "- Who are the stakeholders and what are their needs?\n",
    "    - Telecommunications provider wanting to reduce customer churn.\n",
    "- What business problem are we solving?\n",
    "    - Predict which customers are likely to churn.\n",
    "- What data do we have available?\n",
    "    - Synthetic dataset with customer demographics, usage patterns, service details, and churn labels.\n",
    "\n",
    "**Technical Approach:**\n",
    "- What type of analysis is needed (descriptive, predictive, prescriptive)?\n",
    "    - Predictive analysis.\n",
    "- What are the success criteria?\n",
    "    - Achieve an F1-Score (for Class 1) > 0.70.\n",
    "- What are potential limitations or ethical considerations?\n",
    "    - Class imbalance, data privacy concerns, potentially outliers.\n",
    "\n",
    "**Resources & Timeline:**\n",
    "- What tools and techniques will be used?\n",
    "    - Python, Pandas, Scikit-learn, Logistic Regression, Random Forest.\n",
    "- What is the project timeline?\n",
    "    - Since this is a practice project, set a timeline that allows for thorough exploration and learning.\n",
    "- What external resources might be needed?\n",
    "    - None."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Data Dictionary**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Feature                        | Description                       | Data Type        | Example Values         | Notes                        |\n",
    "|-------------------|--------------------------------------------------|--------------|----------------------------|------------------------------------------|\n",
    "| customer_id       | Unique identifier for each customer              | Integer      | 1001, 1002, 1003, ..., 4000| Primary key                              |\n",
    "| age               | Age of the customer in years                     | Integer      | 18-79                      | Customer demographics                    |\n",
    "| tenure_months     | Number of months the customer has been with the company | Integer | 1-71                    | Loyalty indicator                        |\n",
    "| monthly_bill      | Monthly billing amount in USD                    | Float        | ~20-160                    | Based on normal distribution (Œº=70, œÉ=30)|\n",
    "| total_data_usage_gb | Total data usage in gigabytes per month       | Float        | ~0-90                      | Based on normal distribution (Œº=50, œÉ=20); ~5% missing values |\n",
    "| customer_support_calls | Number of customer support calls made      | Integer      | 0-8+                       | Poisson distribution (Œª=1.5); High calls may indicate dissatisfaction |\n",
    "| contract_type     | Type of customer contract                        | Categorical  | Month-to-Month, Monthly, One Year, 1-year, Two Year, 2-year | Inconsistent formatting (intentional)    |\n",
    "| churn             | Whether the customer churned (left the company)  | Binary       | 0 (Stayed), 1 (Churned)    | Target variable; Imbalanced dataset      |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Quality Notes**\n",
    "- **Missing Values:** Upon completing preliminary analysis of the dataset, it was identified there are missing values in the following columns: total_data_usage_gb.\n",
    "- **Outliers:** There are a few extreme values in the monthly_bill column (e.g., > $200) that may need to be investigated further.\n",
    "- **Class Imbalance:** The target variable 'churn' is imbalanced, with a significantly lower proportion of churned customers (Class 1) compared to non-churned customers (Class 0).\n",
    "- **Data Collection Period:** This data was generated synthetically.\n",
    "- **Known Issues:** None beyond the intentional imperfections for testing purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task 1. Imports & Data Loading**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Task 1a. Import Libraries**\n",
    "- Import packages\n",
    "- Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import scipy.stats as stats\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Task 1b. Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Churn Dataset Generated!\n",
      "Churn Rate: 6.40%\n",
      "   customer_id  age  tenure_months  monthly_bill  total_data_usage_gb  \\\n",
      "0         1001   19             42     45.422406            28.050591   \n",
      "1         1002   53             41     78.016864            55.702603   \n",
      "2         1003   75              4     67.011073            74.798731   \n",
      "3         1004   58             51     43.303750            39.913597   \n",
      "4         1005   27             43    104.898819            78.216551   \n",
      "\n",
      "   customer_support_calls   contract_type  churn  \n",
      "0                       1          2-year      0  \n",
      "1                       2          2-year      0  \n",
      "2                       1          1-year      0  \n",
      "3                       1         Monthly      0  \n",
      "4                       1  month-to-month      0  \n"
     ]
    }
   ],
   "source": [
    "np.random.seed(99) # New seed\n",
    "\n",
    "n_samples = 3000\n",
    "\n",
    "# 1. Base Features\n",
    "data = {\n",
    "    'customer_id': range(1001, 1001 + n_samples),\n",
    "    'age': np.random.randint(18, 80, n_samples),\n",
    "    'tenure_months': np.random.randint(1, 72, n_samples),\n",
    "    'monthly_bill': np.random.normal(70, 30, n_samples),\n",
    "    'total_data_usage_gb': np.random.normal(50, 20, n_samples),\n",
    "    'customer_support_calls': np.random.poisson(1.5, n_samples), # Poisson dist for counts\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Fix negative values from normal distributions\n",
    "df['monthly_bill'] = df['monthly_bill'].apply(lambda x: max(x, 20))\n",
    "df['total_data_usage_gb'] = df['total_data_usage_gb'].apply(lambda x: max(x, 0))\n",
    "\n",
    "# 2. Messy Categorical Feature (The \"Dirty\" Data)\n",
    "# Intentionally inconsistent casing and terminology\n",
    "contract_options = ['Month-to-Month', 'month-to-month', 'Monthly', 'One Year', '1-year', 'Two Year', '2-year']\n",
    "df['contract_type'] = np.random.choice(contract_options, n_samples)\n",
    "\n",
    "# 3. Generating the Target: 'Churn' (0 or 1)\n",
    "# Calculate a 'churn_probability' score based on logic\n",
    "def get_churn_prob(row):\n",
    "    score = 0.15 # Base churn risk (15%)\n",
    "    \n",
    "    # Contract risk (Month-to-month is risky)\n",
    "    if str(row['contract_type']).lower() in ['month-to-month', 'monthly']:\n",
    "        score += 0.30\n",
    "        \n",
    "    # Support Calls risk (High calls = Angry customer)\n",
    "    if row['customer_support_calls'] > 3:\n",
    "        score += 0.40\n",
    "    \n",
    "    # Tenure loyalty (Longer tenure = Lower risk)\n",
    "    score -= (row['tenure_months'] * 0.005)\n",
    "    \n",
    "    # Bill shock (High bill + Low usage = Risk)\n",
    "    if row['monthly_bill'] > 100 and row['total_data_usage_gb'] < 10:\n",
    "        score += 0.25\n",
    "        \n",
    "    # Add noise\n",
    "    score += np.random.normal(0, 0.1)\n",
    "    \n",
    "    return min(max(score, 0), 1) # Clamp between 0 and 1\n",
    "\n",
    "df['churn_prob'] = df.apply(get_churn_prob, axis=1)\n",
    "\n",
    "# Convert probability to binary target (1 = Churn, 0 = Stay)\n",
    "# Note: This creates an IMBALANCED dataset\n",
    "df['churn'] = df['churn_prob'].apply(lambda x: 1 if x > 0.5 else 0)\n",
    "\n",
    "# Drop the probability column so you can't cheat!\n",
    "df.drop(columns=['churn_prob'], inplace=True)\n",
    "\n",
    "# --- INTRODUCTION OF MISSING VALUES --- #\n",
    "# Insert NaNs in 'total_data_usage_gb'\n",
    "nan_indices = np.random.choice(df.index, size=150, replace=False)\n",
    "df.loc[nan_indices, 'total_data_usage_gb'] = np.nan\n",
    "\n",
    "print(\"Churn Dataset Generated!\")\n",
    "print(f\"Churn Rate: {df['churn'].mean():.2%}\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ***End of Plan Section Insights***\n",
    "- What are the key business and technical objectives?\n",
    "    - Predict which customers are likely to churn to help the telecommunications provider reduce customer loss.\n",
    "- What are the main risks or limitations identified?\n",
    "    - Data quality issues (missing values, outliers, class imbalance).\n",
    "- What is your plan for the next stage?\n",
    "    - Move into the Analyze phase to perform exploratory data analysis, clean the data, and prepare it for modeling.\n",
    "- Is the available data sufficient and appropriate for analysis?\n",
    "    - Yes, the dataset contains relevant features for predicting churn, but data quality issues need to be addressed.\n",
    "- What initial hypotheses or questions will guide your exploratory analysis?\n",
    "    - Customers with higher monthly bills and more customer support calls are more likely to churn.\n",
    "    - Longer tenure may correlate with lower churn rates.\n",
    "    - The type of contract may influence churn likelihood.\n",
    "- What data quality issues or gaps need to be addressed before analysis?\n",
    "    - There is missing data in the total_data_usage_gb column and outliers in the monthly_bill column that need to be handled.\n",
    "- What resources, tools, or expertise will be required for the Analyze phase?\n",
    "    - Statistical software (e.g., Python, R), libraries (e.g., pandas, scikit-learn), and expertise in data cleaning and exploratory data analysis techniques.\n",
    "    - Predictive modeling techniques (e.g., Linear Regression, Random Forest)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **Transition to Analyze**\n",
    "\n",
    "With planning complete, begin exploring and cleaning your data to prepare for statistical analysis or modeling.\n",
    "\n",
    "**‚úÖ Before proceeding, ensure you have:**\n",
    "- ‚úì Clearly defined business objectives and success criteria\n",
    "- ‚úì Documented data sources and data dictionary\n",
    "- ‚úì Identified stakeholders and their requirements\n",
    "- ‚úì Assessed ethical considerations and potential biases\n",
    "- ‚úì Established project timeline and resources\n",
    "\n",
    "**üìã Deliverables from Plan stage:**\n",
    "- Project overview with objectives and metrics\n",
    "- Data dictionary with variable descriptions\n",
    "- Initial hypotheses and analysis questions\n",
    "- Risk assessment and mitigation strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Analyze.png\" width=\"75\" height=\"75\" align=left>\n",
    "\n",
    "### **pAce: Analyze**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Questions to reflect on during the Analyze stage** üí≠\n",
    "\n",
    "**Data Relationships & Distributions**\n",
    "- What did you observe about the relationships between the variables?\n",
    "- What did you observe about the distributions of the data?\n",
    "\n",
    "**Data Transformation & Preparation**\n",
    "- What transformations did you make to your data? Why did you choose to make those decisions?\n",
    "- What are some purposes of EDA (Exploratory Data Analysis) before constructing a predictive model?\n",
    "\n",
    "**Resources & References**\n",
    "- What resources do you find yourself using as you complete this stage?\n",
    "\n",
    "**Ethics & Responsible AI**\n",
    "- Are there any ethical considerations in this stage?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task 2. Data Exploration (*Initial EDA and Data Cleaning*)**\n",
    "- Understand the variables\n",
    "- Clean the dataset (missing data, redundant data, outliers)\n",
    "- Perform EDA (analyze relationships between variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Task 2a. Gather Basic Information about the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather some basic information about the dataset\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df.info())\n",
    "print(\"\\nDataset Description:\")\n",
    "print(df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Task 2b. Descriptive Statistics about the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive Statistics\n",
    "print(\"\\nMissing Values in Each Column:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\nOutlier Summary for Horsepower:\")\n",
    "print(df['horsepower'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Task 2c. Rename Columns**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Task 2d. Drop Columns**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Task 2e. Handle Duplicate Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for and handle any duplicate values\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"\\nNumber of duplicate rows: {duplicates}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Task 2f. Handle Missing Values & Incomplete Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle any missing values (e.g., impute with median)\n",
    "df['mileage'].fillna(df['mileage'].median(), inplace=True)\n",
    "print(\"\\nMissing values after imputation:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ***End of Section Insights***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Task 2g. Check Class Imbalances** *(For Classification Problems)*\n",
    "\n",
    "**Note:** Checking class balance early helps inform your EDA strategy and modeling approach. For regression problems, skip this section.\n",
    "\n",
    "| Model                | Importance of Handling Class Imbalances | Why?                                                                                                                                                                                                  |\n",
    "|----------------------|-----------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Decision Trees (DT)  | Moderate                                | Decision Trees can handle some imbalance due to splitting on feature importance, but severe imbalance may bias splits toward the majority class. Consider class weighting or resampling if imbalance is high. |\n",
    "| Random Forests (RF)  | Moderate                                | Random Forests are more robust than single trees but can still favor the majority class with significant imbalance. Use class weighting, balanced subsampling, or SMOTE for better minority class prediction. |\n",
    "| Linear Regression    | Low                                     | Linear Regression is not used for classification, so class imbalance is not directly relevant. For regression with imbalanced targets, focus on distributional skew rather than class imbalance.            |\n",
    "| Logistic Regression  | High                                    | Logistic Regression is sensitive to class imbalance, which can bias decision boundaries and reduce minority class recall. Use class weighting, oversampling, or undersampling to address imbalance.         |\n",
    "| XGBoost             | Moderate to High                        | XGBoost is robust to some imbalance due to boosting, but severe imbalance can still bias results. Adjust `scale_pos_weight`, use custom metrics (AUC-ROC), or resample data for best results.               |\n",
    "\n",
    "**Note:** Checking class balance early helps inform your EDA strategy and modeling approach. For regression problems, skip this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task 3. Data Exploration *(Continue EDA)***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Check Class Imbalance in the Target Variable**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Task 3a. Data Visualizations** üìä\n",
    "\n",
    "This section provides comprehensive visualizations to understand data distributions, relationships, and patterns.\n",
    "\n",
    "**Note**: Visualizations in this section can instead be created in other tools like Tableau or Power BI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Univariate Visualizations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for categorical variable brand_tier\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(data=df, x='brand_tier', order=df['brand_tier'].value_counts().index)\n",
    "plt.title('Distribution of Brand Tier')\n",
    "plt.xlabel('Brand Tier')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for categorical variable fuel_type\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(data=df, x='fuel_type', order=df['fuel_type'].value_counts().index)\n",
    "plt.title('Distribution of Fuel Type')\n",
    "plt.xlabel('Fuel Type')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Boolean Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for binary categorical variable accident_history\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(data=df, x='accident_history', order=[0, 1])\n",
    "plt.title('Distribution of Accident History')\n",
    "plt.xlabel('Accident History (0=No, 1=Yes)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Discrete Numeric Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for discrete numeric variable age_years\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(data=df, x='age_years', order=sorted(df['age_years'].unique()))\n",
    "plt.title('Distribution of Car Age (Years)')\n",
    "plt.xlabel('Age (Years)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for discrete numeric variable horsepower\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(df['horsepower'], bins=75, kde=True)\n",
    "plt.title('Distribution of Horsepower')\n",
    "plt.xlabel('Horsepower')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Continuous Numeric Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for continuous numeric variable mileage\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(df['mileage'], bins=30, kde=True)\n",
    "plt.title('Distribution of Mileage')\n",
    "plt.xlabel('Mileage')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for continuous numeric variable price\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(df['price'], bins=30, kde=True)\n",
    "plt.title('Distribution of Price')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Bivariate Visualizations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare price across brand_tier\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(data=df, x='brand_tier', y='price', order=['Economy', 'Mid-Range', 'Luxury'])\n",
    "plt.title('Price Distribution by Brand Tier')\n",
    "plt.xlabel('Brand Tier')\n",
    "plt.ylabel('Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare price across fuel_type\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(data=df, x='fuel_type', y='price', order=['Gasoline', 'Diesel', 'Electric'])\n",
    "plt.title('Price Distribution by Fuel Type')\n",
    "plt.xlabel('Fuel Type')\n",
    "plt.ylabel('Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Feature Comparisons**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Multivariate Visualizations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Feature Comparisons**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ***End of Section Insights***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task 3 (continued). Data Preparation & Feature Engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Task 3b. Feature Engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Task 3c. First Iteration of Feature Selection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Task 3d. Investigate Features Further (Optional)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Task 3e. Outliers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers can have varying impacts depending on the modeling approach. Always visualize and assess outliers before modeling. Consider robust methods or transformations if outliers are present.\n",
    "\n",
    "| Model               | Importance of Handling Outliers | Why?                                                                                                                                                                                                 |\n",
    "|---------------------|---------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Decision Trees (DT) | Low                             | Decision Trees split data based on thresholds, making them inherently robust to outliers. Extreme outliers may slightly influence split thresholds, especially in shallow trees.                    |\n",
    "| Random Forests (RF) | Low to Moderate                 | Random Forests average predictions across multiple trees, reducing the influence of outliers. Consistent outliers across samples may slightly affect feature importance rankings.                   |\n",
    "| Linear Regression   | High                            | Outliers can disproportionately influence the regression line, distorting coefficients and residuals, leading to poor model performance and interpretability.                                      |\n",
    "| Logistic Regression | Moderate to High                | Outliers can affect the decision boundary, especially if they dominate the feature space. The sigmoid function reduces sensitivity, but extreme outliers can still skew predictions.               |\n",
    "| XGBoost             | Moderate                        | XGBoost is generally robust to outliers due to its tree-based nature and regularization. However, dominant outliers can influence split thresholds and feature importance, especially early on.     |\n",
    "| Statistical Testing | High                            | Outliers can strongly affect tests (t-tests, ANOVA, correlation) by inflating variance and distorting means. Non-parametric tests (e.g., Mann-Whitney U, Wilcoxon) are less sensitive. Always check for outliers and consider robust alternatives if needed. |\n",
    "\n",
    "**Tip:**  \n",
    "- Use boxplots or histograms to visually inspect outliers.\n",
    "- Consider winsorizing, transformation, or robust models if outliers are problematic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Check for Outliers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for outliers in horsepower\n",
    "Q1 = df['horsepower'].quantile(0.25)\n",
    "Q3 = df['horsepower'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "outliers = df[(df['horsepower'] < lower_bound) | (df['horsepower'] > upper_bound)]\n",
    "print(f\"\\nNumber of outliers in horsepower: {outliers.shape[0]}\")\n",
    "print(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a boxplot to visualize outliers in the 'horsepower' variable.\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(data=df, x='horsepower')\n",
    "plt.title('Boxplot of Horsepower to Visualize Outliers')\n",
    "plt.xlabel('Horsepower')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Manage Outliers with IQR Method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle outliers with the IQR method\n",
    "df = df[(df['horsepower'] >= lower_bound) & (df['horsepower'] <= upper_bound)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Task 3f. Check Assumptions (Data-Level)**\n",
    "\n",
    "These checks are performed **before modeling** to:\n",
    "- Validate suitability for statistical tests (t-tests, ANOVA, correlation)\n",
    "- Guide data transformations and preprocessing\n",
    "- Inform feature selection decisions\n",
    "\n",
    "**Note:** For predictive models, model-specific assumptions (linearity, homoscedasticity of residuals, normality of residuals) are checked **after** model development in Task 4b using residual diagnostics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Normality**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Continuous Numeric Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check normality of all continuous variables using Q-Q plots\n",
    "continuous_vars = ['mileage', 'price', 'horsepower']\n",
    "for var in continuous_vars:\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    stats.probplot(df[var], dist=\"norm\", plot=plt)\n",
    "    plt.title(f'Q-Q Plot for {var}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Discrete Numeric Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check normality of all discrete numeric variables using Q-Q plots\n",
    "discrete_vars = ['age_years']\n",
    "for var in discrete_vars:\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    stats.probplot(df[var], dist=\"norm\", plot=plt)\n",
    "    plt.title(f'Q-Q Plot for {var}')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Homogeneity of Variance** *(Equal Variance)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Independence**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing for independence between variables and observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Sample Size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that sample size is sufficient for analysis\n",
    "n_rows, n_cols = df.shape\n",
    "print(f\"\\nDataset contains {n_rows} rows and {n_cols} columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Task 3g. Statistical Testing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Null Hypothesis (H‚ÇÄ):** There is no statistically significant difference in price between cars with and without an accident history.\n",
    "\n",
    "**Alternative Hypothesis (H‚Çê):** There is a statistically significant difference in price between cars with and without an accident history."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Statistical Testing Metrics Reference** üìä\n",
    "\n",
    "- **P-value:** Probability of observing results as extreme as those measured, assuming the null hypothesis is true (commonly, < 0.05 indicates statistical significance).\n",
    "- **Z-statistic:** Standardized value showing how many standard deviations a sample mean is from the population mean; used for large samples or when population variance is known.\n",
    "- **T-statistic:** Measures the difference between group means relative to sample variability; used for smaller samples or when population variance is unknown.\n",
    "- **Effect Size (Cohen's d):** Quantifies the magnitude of the difference between groups, regardless of sample size.\n",
    "  - Small: 0.2, Medium: 0.5, Large: 0.8\n",
    "- **Confidence Interval:** Range of values within which the true population parameter is likely to fall, with a given level of confidence (e.g., 95%).\n",
    "- **Statistical Power:** Probability that a test will detect a true effect when it exists (aim for 80%+ to reduce risk of Type II error).\n",
    "\n",
    "*Tip: Always report both statistical significance (p-value) and practical significance (effect size/confidence interval) for context.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Run Statistical Tests**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine if there is a statistically significant difference in price between cars with accident_history = 0 vs accident_history = 1.\n",
    "group0 = df[df['accident_history'] == 0]['price']\n",
    "group1 = df[df['accident_history'] == 1]['price']\n",
    "t_stat, p_value = stats.ttest_ind(group0, group1, equal_var=False)\n",
    "print(f\"\\nT-statistic: {t_stat}, P-value: {p_value}\")\n",
    "if p_value < 0.05:\n",
    "    print(\"Reject the null hypothesis: There is a statistically significant difference in price based on accident history.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: No statistically significant difference in price based on accident history.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Check Statistical Significance of Numeric, Binary and Categorical Features**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Method                        | Description                                                                 | Importance for Decision Trees (DT) | Importance for Random Forests (RF) | Importance for Linear Regression | Importance for Logistic Regression | Importance for XGBoost | Why?                                                                                                   |\n",
    "|-------------------------------|-----------------------------------------------------------------------------|------------------------------------|------------------------------------|-----------------------------------|-------------------------------------|-------------------------|-------------------------------------------------------------------------------------------------------|\n",
    "| Statistical Significance Tests | Evaluates the relationship between individual features and the target variable (e.g., t-tests, chi-square). | Low                                | Low to Moderate                   | High                              | High                                | Low to Moderate         | Essential for regression models to identify predictive features. For tree-based models, less critical due to built-in feature selection, but can help with interpretability and initial screening. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Check Statistical Significance of Features for Modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check statistical significance of independent variables compared to dependent variable price to determine which can be dropped prior to modeling.\n",
    "independent_vars = ['brand_tier', 'age_years', 'horsepower', 'mileage', 'fuel_type', 'accident_history']\n",
    "for var in independent_vars:\n",
    "    if df[var].dtype == 'object' or len(df[var].unique()) <= 10:\n",
    "        # Categorical variable - ANOVA\n",
    "        groups = [df[df[var] == level]['price'] for level in df[var].unique()]\n",
    "        f_stat, p_val = stats.f_oneway(*groups)\n",
    "        print(f\"\\nANOVA for {var} - F-statistic: {f_stat}, P-value: {p_val}\")\n",
    "    else:\n",
    "        # Continuous variable - Correlation\n",
    "        corr, p_val = stats.pearsonr(df[var], df['price'])\n",
    "        print(f\"\\nCorrelation for {var} - Correlation coefficient: {corr}, P-value: {p_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Remove Statistically Insignificant Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop statistically insignificant variables based on p-value threshold of 0.05\n",
    "df.drop(columns=['fuel_type'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Task 3h. Variable Skewness**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model                | Importance of Handling Skewness | Why?                                                                                                   |\n",
    "|----------------------|---------------------------------|--------------------------------------------------------------------------------------------------------|\n",
    "| Decision Trees (DT)  | Low                             | Decision Trees split data by thresholds and are robust to skewed distributions. Extreme skewness may cause imbalanced splits or affect interpretability. |\n",
    "| Random Forests (RF)  | Low                             | Random Forests inherit robustness from Decision Trees. Severe skewness is rarely problematic but can occasionally contribute to overfitting or biased feature importance. |\n",
    "| Linear Regression    | High                            | Linear Regression is sensitive to skewed features, which can distort coefficients and residuals. Transformations (e.g., log, Box-Cox) are often necessary for valid inference. |\n",
    "| Logistic Regression  | High                            | Logistic Regression assumes linearity in the logit; skewed features can reduce model accuracy and interpretability. Transformations are recommended. |\n",
    "| XGBoost              | Moderate                        | XGBoost is robust to skewness due to its tree-based nature, but highly skewed features can influence split thresholds or dominate feature importance. Transformations may improve results. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Check Variable Skewness**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check skewness of all numeric variables\n",
    "numeric_vars = ['age_years', 'horsepower', 'mileage', 'price']\n",
    "for var in numeric_vars:\n",
    "    skewness = df[var].skew()\n",
    "    if abs(skewness) > 0.75:\n",
    "        print(f\"\\n{var} is highly skewed (skewness: {skewness}). Consider transformation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Manage Variable Skewness**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Task 3i. Encode Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables for modeling\n",
    "df = pd.get_dummies(df, columns=['brand_tier'], drop_first=True, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print dataset after preprocessing\n",
    "print(\"\\nDataset after preprocessing:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Task 3j. Remove Highly Correlated Features (Correlation Heatmaps & VIF)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model Type           | Importance | Why?                                                                                                                                                                                                  |\n",
    "|----------------------|------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Decision Trees       | Moderate   | Decision Trees are not sensitive to multicollinearity for prediction, but correlated features can affect feature importance rankings, which matters for interpretation and feature selection.           |\n",
    "| Random Forests       | Low        | Random Forests are robust to multicollinearity, but correlated features may still bias feature importance scores. Consider removing highly correlated features if interpretability is important.      |\n",
    "| Linear Regression    | High       | Multicollinearity causes unstable coefficients, inflated standard errors, and unreliable interpretations. VIF is critical for diagnosing and addressing this issue.                                   |\n",
    "| Logistic Regression  | High       | Like linear regression, logistic regression is sensitive to multicollinearity, leading to unstable coefficients and interpretability challenges. VIF is an important diagnostic tool.                 |\n",
    "| XGBoost              | Low        | XGBoost is generally robust to multicollinearity due to tree-based splits and built-in regularization (L1/L2). Correlated features may affect feature importance but rarely degrade predictive power. |\n",
    "\n",
    "**Notes:**\n",
    "1. For tree-based models, multicollinearity does not harm predictive performance but can bias feature importance, which is relevant for interpretation.\n",
    "2. For regression models, always check VIF and remove/reduce highly correlated features.\n",
    "3. For XGBoost, regularization helps, but review feature importance for interpretability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Check for Multicollinearity with Correlation Heatmaps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for multicollinearity among independent variables with a correlation matrix plot.\n",
    "plt.figure(figsize=(10, 8))\n",
    "corr_matrix = df.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', square=True)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Check For Multicollinearity (VIF)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for multicollinearity with VIF.\n",
    "X = df.drop(columns=['car_id', 'price'])\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = X.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "print(\"\\nVariance Inflation Factor (VIF) for each feature:\")\n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Remove Highly Correlated Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove feature 'age_years' due to high correlation with 'mileage' and high VIF\n",
    "df.drop(columns=['mileage'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ***End of Analyze Section Insights***\n",
    "- What are the most important data quality or distribution issues discovered?\n",
    "    - Outliers in horsepower and missing values in mileage.\n",
    "- What features or variables require special attention in the next stage?\n",
    "    - With outliers and missing values being addressed, there shouldn't be a significant amount of special handling needed for remaining features.\n",
    "- What is your plan for feature selection or engineering?\n",
    "    - Initial feature selection was completed based on statistical significance and correlation analysis. Further feature engineering may be explored in the Construct phase utilizing domain knowledge and additional feature elimination methods.\n",
    "- Were any unexpected patterns, trends, or anomalies identified?\n",
    "    - Beyond the outliers and missing values, no unexpected patterns were observed.\n",
    "- How did handling missing values, outliers, or skewness affect the dataset?\n",
    "    - The number of outliers were few and were managed without significant impact on the dataset. Missing values in mileage were imputed using the median, which preserved the overall distribution.\n",
    "- Are there any features that may introduce bias or ethical concerns?\n",
    "    - None identified.\n",
    "- What limitations remain in the data after cleaning and transformation?\n",
    "    - The synthetic nature of the dataset may limit real-world applicability, but it is sufficient for testing the analysis template.\n",
    "- What assumptions have you made during EDA that should be revisited later?\n",
    "    - Assumed that missing mileage values were random and could be imputed without biasing the dataset.\n",
    "- What additional data or context would improve the analysis?\n",
    "    - Real-world data with more variability and complexity would enhance the analysis.\n",
    "- What modeling challenges do you anticipate based on your EDA findings?\n",
    "    - With outliers, missing data and multicollinearity being addressed, there are no significant anticipated challenges at this point.\n",
    "- Are there specific features or data transformations that may require special handling in the modeling phase?\n",
    "    - Outliers in horsepower have been managed, and mileage hsa been imputed, as well as multicollinearity addressed. There shouldn't be any features that require spceial handling at this point.\n",
    "- What criteria will you use to evaluate feature selection and model performance?\n",
    "    - RMSE and R-Squared for regression performance.\n",
    "- How will your EDA findings influence your choice of modeling techniques?\n",
    "    - Due to the few outliers and missing data being addressed, as well as remaining features having low multi-collinearity, standard modeling techniques like linear regression will be appropriate.\n",
    "- Are there any features you expect to be especially predictive or problematic for modeling?\n",
    "    - I expect all features to have some predictive power, but I would expect age_years and accident_history to be especially predictive.\n",
    "- What steps will you take if initial models do not perform as expected?\n",
    "    - Revisit feature engineering, consider additional transformations, or explore alternative modeling techniques.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Save Analysis-Ready Dataset**\n",
    "\n",
    "**Checkpoint:** Save your fully prepared dataset with all transformations, feature engineering, and cleaning applied. This dataset is ready for modeling.\n",
    "\n",
    "**Recommended naming:** `{project_name}_analysis_ready.csv` or `.pkl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataset.\n",
    "df.to_csv('used_car_value_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **Transition to Construct**\n",
    "\n",
    "With your data prepared and features selected, proceed to model development, validation, and post-model assumption testing.\n",
    "\n",
    "**‚úÖ Before proceeding, ensure you have:**\n",
    "- ‚úì Completed data cleaning (missing values, duplicates, outliers handled)\n",
    "- ‚úì Performed comprehensive EDA with visualizations\n",
    "- ‚úì Engineered and selected relevant features\n",
    "- ‚úì Checked statistical assumptions and conducted tests\n",
    "- ‚úì Addressed class imbalance if applicable\n",
    "- ‚úì Saved analysis-ready dataset\n",
    "\n",
    "**üìã Deliverables from Analyze stage:**\n",
    "- Clean, transformed dataset ready for modeling\n",
    "- EDA insights and patterns documented\n",
    "- Statistical test results (if applicable)\n",
    "- Feature engineering rationale\n",
    "- List of features selected for modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Construct.png\" width=\"75\" height=\"75\" align=left>\n",
    "\n",
    "## **paCe: Construct**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Questions to reflect on during the Construct stage** üí≠\n",
    "**Data & Model Diagnostics**\n",
    "- Do you observe anything unusual?\n",
    "- Have all the assumptions been met?\n",
    "- How well does the model fit the data?\n",
    "- How will you validate model performance (e.g., cross-validation, test set)?\n",
    "- What criteria will you use to determine if the model is successful?\n",
    "\n",
    "**Feature Selection & Rationale**\n",
    "- Which independent variables did you select for the model, and what was your rationale?\n",
    "- Are there any features or data transformations that require special handling in modeling?\n",
    "\n",
    "**Model Improvement & Iteration**\n",
    "- Can the model be improved? Are there any changes you would make?\n",
    "\n",
    "**Resources & References**\n",
    "- What resources did you consult during this stage? (Please include links.)\n",
    "\n",
    "**Ethics & Responsible AI**\n",
    "- Are there any ethical considerations at this stage?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task 4. Model Development**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Task 4a. Prepare Data for Modeling**\n",
    "\n",
    "**Key Activities:**\n",
    "- Define features (X) and target variable (y)\n",
    "- Split data into training and test sets\n",
    "- Set up cross-validation strategy\n",
    "- Apply feature scaling/normalization if needed (for regression models)\n",
    "- Handle any remaining data preparation specific to modeling\n",
    "\n",
    "**Best Practices:**\n",
    "- Use stratified split for classification to preserve class distribution\n",
    "- Typical split: 70-80% training, 20-30% test\n",
    "- Set random_state for reproducibility\n",
    "- Ensure no data leakage (fit transformations only on training data)\n",
    "\n",
    "**Note:** For tree-based models (DT, RF, XGBoost), feature scaling is not required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Model Selection Guidance** üéØ\n",
    "\n",
    "**Quick Model Selection Guide:**\n",
    "\n",
    "| Issue                   | Linear/Logistic Regression                | Tree-Based Models (DT/RF/XGBoost)           |\n",
    "|-------------------------|-------------------------------------------|---------------------------------------------|\n",
    "| **Multicollinearity**   | ‚ö†Ô∏è **Critical** ‚Äì Remove correlated features | ‚úÖ **Low impact** ‚Äì Models handle naturally  |\n",
    "| **Feature Scaling**     | ‚ö†Ô∏è **Required** ‚Äì Standardize features      | ‚úÖ **Not needed** ‚Äì Tree splits are scale-invariant |\n",
    "| **Missing Values**      | ‚ö†Ô∏è **Must handle** ‚Äì Impute before modeling | üî∂ **Some tolerance** ‚Äì XGBoost handles natively |\n",
    "| **Outliers**            | ‚ö†Ô∏è **Sensitive** ‚Äì Consider removal/transformation | ‚úÖ **Robust** ‚Äì Tree splits minimize impact  |\n",
    "| **Feature Interactions**| ‚ö†Ô∏è **Manual** ‚Äì Must engineer interactions | ‚úÖ **Automatic** ‚Äì Naturally captures interactions |\n",
    "| **Interpretability**    | ‚úÖ **High** ‚Äì Clear coefficient interpretation | üî∂ **Medium** ‚Äì Feature importance available |\n",
    "\n",
    "**Choose Linear/Logistic when:** You need high interpretability and have clean, well-prepared data.\n",
    "\n",
    "**Choose Tree-based when:** You want robustness, automatic feature handling, and strong predictive performance.\n",
    "\n",
    "*Tip: Consider your business objectives, data quality, and need for interpretability when selecting a model.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Task 4b. Build and Iterate Models**\n",
    "\n",
    "**Key Activities:**\n",
    "- Select appropriate modeling techniques based on data characteristics and business objectives\n",
    "- Build and tune initial models using cross-validation and hyperparameter optimization\n",
    "- Check model assumptions and diagnose potential issues (e.g., overfitting, multicollinearity, class imbalance)\n",
    "- Evaluate model performance using relevant metrics (e.g., accuracy, recall, AUC, F1-score)\n",
    "- Iterate on feature selection and model parameters to improve performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Model Evaluation Metrics Reference** üìä\n",
    "\n",
    "**For Classification Models:**\n",
    "- **AUC (ROC-AUC):** Area under the ROC curve; measures ability to distinguish classes (higher = better).\n",
    "- **Precision:** Proportion of predicted positives that are actual positives (focuses on false positives).\n",
    "- **Recall (Sensitivity):** Proportion of actual positives correctly identified (focuses on false negatives).\n",
    "- **Accuracy:** Proportion of all predictions that are correct (can be misleading with imbalanced classes).\n",
    "- **F1-score:** Harmonic mean of precision and recall; balances false positives and false negatives.\n",
    "- **Confusion Matrix:** Table showing counts of true positives, false positives, true negatives, and false negatives.\n",
    "\n",
    "**For Regression Models:**\n",
    "- **RMSE (Root Mean Squared Error):** Square root of average squared differences between predicted and actual values (penalizes large errors).\n",
    "- **MAE (Mean Absolute Error):** Average absolute differences between predicted and actual values (less sensitive to outliers).\n",
    "- **R¬≤ (Coefficient of Determination):** Proportion of variance in dependent variable explained by model.\n",
    "- **Adjusted R¬≤:** R¬≤ adjusted for number of predictors; penalizes unnecessary complexity.\n",
    "\n",
    "*Tip: Always select metrics that align with your business objectives and the problem context (e.g., use recall for churn prediction if missing a churned client is costly).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Linear Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Linear Regression model.\n",
    "X = df.drop(columns=['car_id', 'price'])\n",
    "y = df['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the models performance using MSE, RMSE, and R2.\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"\\nModel Performance:\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"R-squared (R2 ): {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the models coefficients.\n",
    "coefficients = pd.DataFrame({'Feature': X.columns, 'Coefficient': model.coef_})\n",
    "print(\"\\nModel Coefficients:\")\n",
    "print(coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Model Assumptions\n",
    "\n",
    "After developing your linear regression model, check the following assumptions:\n",
    "\n",
    "**Linearity & Homoscedasticity** (combined check)\n",
    "- Residuals should scatter randomly around zero with consistent spread\n",
    "- *Check with residual vs. fitted value plots*\n",
    "\n",
    "**Independence of Residuals**\n",
    "- Residuals are independent (no autocorrelation)\n",
    "- *Test with autocorrelation plot or Durbin-Watson statistic*\n",
    "\n",
    "**Normality of Residuals**\n",
    "- Residuals are approximately normally distributed\n",
    "- *Assess with Q-Q plots or Shapiro-Wilk test*\n",
    "\n",
    "**No Multicollinearity**\n",
    "- Predictors are not highly correlated with each other\n",
    "- *Already verified in Task 3j with VIF - reference those results*\n",
    "\n",
    "*Tip: Violations may require data transformation, feature engineering, or alternative modeling approaches.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Linearity & Homoscedasticity of residuals between predictors and the outcome variable.\n",
    "residuals = y_test - y_pred\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_pred, residuals)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.title('Residuals vs Predicted Values')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that Residuals are independent (no autocorrelation)\n",
    "plt.figure(figsize=(8,6))  # Changed from plt.Figure to plt.figure (lowercase 'f')\n",
    "plt.acorr(residuals, maxlags=40)\n",
    "plt.axhline(y=0, color='red', linestyle='--', linewidth=1)  # Add reference line at y=0\n",
    "plt.xlabel('Lag')\n",
    "plt.ylabel('Autocorrelation')\n",
    "plt.title('Autocorrelation of Residuals')\n",
    "plt.grid(True, alpha=0.3)  # Add subtle gridlines\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check normality of residuals with Q-Q plot.\n",
    "plt.figure(figsize=(6, 6))\n",
    "stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "plt.title('Q-Q Plot of Residuals')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Logistic Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Model Assumptions üìä\n",
    "\n",
    "After developing your logistic regression model, check the following assumptions:\n",
    "\n",
    "**1. Linearity of the Logit**\n",
    "- Predictors have a linear relationship with the log odds of the outcome\n",
    "- *Check with Box-Tidwell test or by plotting predictor vs. logit*\n",
    "\n",
    "**2. Independence of Observations**\n",
    "- Observations are independent of each other (no clustering or autocorrelation)\n",
    "- *Consider data collection method and temporal dependencies*\n",
    "\n",
    "**3. No Multicollinearity**\n",
    "- Predictors are not highly correlated with each other\n",
    "- *Already verified in Task 3j with VIF - reference those results*\n",
    "\n",
    "**4. No Extreme Outliers or Influential Points**\n",
    "- Outliers do not unduly influence the model\n",
    "- *Assess with Cook's distance, leverage plots, and standardized residuals*\n",
    "\n",
    "**5. Large Sample Size**\n",
    "- Sufficient data for stable coefficient estimates\n",
    "- *Rule of thumb: ‚â•10-15 events per predictor variable for each outcome class*\n",
    "\n",
    "**6. Binary or Ordinal Outcome**\n",
    "- Dependent variable must be binary (or ordinal for ordinal logistic regression)\n",
    "- *Verify target variable has exactly 2 classes*\n",
    "\n",
    "*Tip: Violations may require data transformation, removing influential observations, regularization (L1/L2), or alternative modeling approaches.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Decision Tree**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save Model Iteration Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate SHAP Values for Feature Importance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Aspect**              | **Description**                                                                                           | **How to Read in SHAP Plot**                                                                                   |\n",
    "|-------------------------|-----------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------|\n",
    "| **Feature Ranking**     | Features are ordered by overall impact on model predictions.                                              | Top features are most influential; read from top to bottom.                                                     |\n",
    "| **SHAP Value (X-axis)** | Amount each feature value increases or decreases the prediction for each sample.                          | Dots left of center lower prediction; dots right of center raise prediction.                                    |\n",
    "| **Color Gradient**      | Shows the original feature value for each sample.                                                         | Blue = low value, Red/Pink = high value.                                                                        |\n",
    "| **Spread**              | Shows how much feature impact varies across samples.                                                      | Wide spread = strong/variable effect; tight cluster = less impact.                                              |\n",
    "| **Direction**           | Indicates if high or low feature values drive predictions up or down.                                     | If red dots are mostly right, high values increase prediction; if left, high values decrease prediction.        |\n",
    "| **Summary**             | Identifies which features matter most and how they influence predictions.                                 | Use plot to explain model behavior and feature effects to stakeholders.                                         |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove Features with Low Importance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance Across Model Types\n",
    "\n",
    "| Method             | Description                                                                                     | Importance for DT Models | Importance for RF Models | Importance for Linear Regression | Importance for Logistic Regression | Importance for XGBoost |\n",
    "|--------------------|-------------------------------------------------------------------------------------------------|--------------------------|--------------------------|----------------------------------|-------------------------------------|-----------------------|\n",
    "| Feature Importance | Uses model-specific metrics (e.g., Gini impurity, information gain) to rank feature importance. | High                     | High                     | Low                              | Low                                 | High                  |\n",
    "\n",
    "### Feature Selection Methods Comparison\n",
    "\n",
    "| Method                          | Description                                                                                     | Evaluation Approach                | Feature Interactions         | Computational Cost         | Flexibility                                  | Use Case                                                      |\n",
    "|----------------------------------|-------------------------------------------------------------------------------------------------|------------------------------------|-----------------------------|----------------------------|-----------------------------------------------|---------------------------------------------------------------|\n",
    "| Feature Importance Threshold     | Selects features above a set importance threshold.                                              | Static (single evaluation)         | Ignores                     | Low                        | Relies on fixed threshold                     | Fast, simple screening                                       |\n",
    "| RFE (Recursive Feature Elimination) | Iteratively removes least important features, retraining the model each time.                 | Iterative (multiple retrainings)   | Considers dynamically       | High                       | Can specify number of features                | When feature interactions matter                              |\n",
    "| RFECV                            | RFE with cross-validation to find optimal feature set.                                         | Iterative + Cross-validation       | Considers dynamically       | Very High                   | Automatically determines optimal features     | Automated optimal selection                                   |\n",
    "\n",
    "*Tip: Use Table 1 to decide if feature importance is relevant for your model, then Table 2 to select the best feature selection method for your workflow.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Model Assumptions üå≥\n",
    "\n",
    "After developing your decision tree model, consider the following best practices and checks:\n",
    "\n",
    "**1. Sufficient Sample Size**\n",
    "- Adequate data to create meaningful splits and avoid overfitting\n",
    "- *Ensure each terminal node has sufficient observations (min_samples_leaf)*\n",
    "\n",
    "**2. Feature Relevance**\n",
    "- Important features are included; irrelevant features may reduce performance\n",
    "- *Review feature importance scores and remove low-impact features*\n",
    "\n",
    "**3. Check for Overfitting**\n",
    "- Model may memorize training data rather than learn patterns\n",
    "- *Use cross-validation, prune tree, or limit max_depth and min_samples_split*\n",
    "\n",
    "**4. Handle Class Imbalance (Classification)**\n",
    "- Severe imbalance can bias splits toward majority class\n",
    "- *Use class_weight='balanced', SMOTE, or stratified sampling*\n",
    "\n",
    "**5. No Multicollinearity Requirement**\n",
    "- Trees handle correlated features naturally\n",
    "- *Note: Correlated features may affect feature importance interpretation*\n",
    "\n",
    "**6. Interpretability Considerations**\n",
    "- Feature importance may favor high-cardinality or continuous variables\n",
    "- *Review importance scores critically and validate with domain knowledge*\n",
    "\n",
    "**7. Hyperparameter Tuning**\n",
    "- Model performance depends on proper parameter selection\n",
    "- *Use GridSearchCV or RandomizedSearchCV for max_depth, min_samples_split, min_samples_leaf, max_features*\n",
    "\n",
    "**8. Validation Strategy**\n",
    "- Always evaluate on holdout/test set to assess generalization\n",
    "- *Check for data leakage and ensure train/test split is representative*\n",
    "\n",
    "**Advantages of Decision Trees:**\n",
    "- No distributional assumptions (normality, homoscedasticity not required)\n",
    "- Robust to outliers due to threshold-based splits\n",
    "- Handles missing values (some implementations)\n",
    "- Captures non-linear relationships and feature interactions automatically\n",
    "\n",
    "*Tip: Document any assumption violations and mitigation steps for transparency and reproducibility.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Random Forest**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Buld the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save Model Iteration Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove Features with Low Importance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance Across Model Types\n",
    "\n",
    "| Method             | Description                                                                                     | Importance for DT Models | Importance for RF Models | Importance for Linear Regression | Importance for Logistic Regression | Importance for XGBoost |\n",
    "|--------------------|-------------------------------------------------------------------------------------------------|--------------------------|--------------------------|----------------------------------|-------------------------------------|-----------------------|\n",
    "| Feature Importance | Uses model-specific metrics (e.g., Gini impurity, information gain) to rank feature importance. | High                     | High                     | Low                              | Low                                 | High                  |\n",
    "\n",
    "### Feature Selection Methods Comparison\n",
    "\n",
    "| Method                          | Description                                                                                     | Evaluation Approach                | Feature Interactions         | Computational Cost         | Flexibility                                  | Use Case                                                      |\n",
    "|----------------------------------|-------------------------------------------------------------------------------------------------|------------------------------------|-----------------------------|----------------------------|-----------------------------------------------|---------------------------------------------------------------|\n",
    "| Feature Importance Threshold     | Selects features above a set importance threshold.                                              | Static (single evaluation)         | Ignores                     | Low                        | Relies on fixed threshold                     | Fast, simple screening                                       |\n",
    "| RFE (Recursive Feature Elimination) | Iteratively removes least important features, retraining the model each time.                 | Iterative (multiple retrainings)   | Considers dynamically       | High                       | Can specify number of features                | When feature interactions matter                              |\n",
    "| RFECV                            | RFE with cross-validation to find optimal feature set.                                         | Iterative + Cross-validation       | Considers dynamically       | Very High                   | Automatically determines optimal features     | Automated optimal selection                                   |\n",
    "\n",
    "*Tip: Use Table 1 to decide if feature importance is relevant for your model, then Table 2 to select the best feature selection method for your workflow.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Model Assumptions üå≤\n",
    "\n",
    "After developing your random forest model, consider the following best practices and checks:\n",
    "\n",
    "**1. Sufficient Sample Size**\n",
    "- Adequate data to create meaningful splits across multiple trees\n",
    "- *Ensure sufficient observations per terminal node across the forest*\n",
    "\n",
    "**2. Feature Relevance**\n",
    "- Important features are included; irrelevant features may dilute performance\n",
    "- *Review feature importance scores and remove low-impact features*\n",
    "\n",
    "**3. Check for Overfitting**\n",
    "- Model may memorize training patterns despite ensemble averaging\n",
    "- *Use out-of-bag (OOB) error, cross-validation, or limit n_estimators, max_depth, min_samples_split*\n",
    "\n",
    "**4. Handle Class Imbalance (Classification)**\n",
    "- Severe imbalance can bias predictions toward majority class\n",
    "- *Use class_weight='balanced', balanced_subsample, or SMOTE*\n",
    "\n",
    "**5. No Multicollinearity Requirement**\n",
    "- Random forests handle correlated features naturally through random feature selection\n",
    "- *Note: Correlated features may affect feature importance interpretation*\n",
    "\n",
    "**6. Interpretability Considerations**\n",
    "- Feature importance may favor high-cardinality or continuous variables\n",
    "- *Review importance scores critically, validate with domain knowledge, and consider permutation importance*\n",
    "\n",
    "**7. Hyperparameter Tuning**\n",
    "- Model performance depends on proper parameter selection\n",
    "- *Use GridSearchCV or RandomizedSearchCV for n_estimators, max_depth, min_samples_split, min_samples_leaf, max_features*\n",
    "\n",
    "**8. Validation Strategy**\n",
    "- Always evaluate on holdout/test set to assess generalization\n",
    "- *Check for data leakage and ensure train/test split is representative*\n",
    "\n",
    "**Advantages of Random Forests:**\n",
    "- No distributional assumptions (normality, homoscedasticity not required)\n",
    "- Robust to outliers due to ensemble averaging and threshold-based splits\n",
    "- Handles missing values (some implementations)\n",
    "- Captures non-linear relationships and feature interactions automatically\n",
    "- Reduces overfitting compared to single decision trees\n",
    "\n",
    "*Tip: Document any assumption violations and mitigation steps for transparency and reproducibility.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate SHAP (SHapley Additive exPlanations**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **XGBoost**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Buld the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove Features with Low Importance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance Across Model Types\n",
    "\n",
    "| Method             | Description                                                                                     | Importance for DT Models | Importance for RF Models | Importance for Linear Regression | Importance for Logistic Regression | Importance for XGBoost |\n",
    "|--------------------|-------------------------------------------------------------------------------------------------|--------------------------|--------------------------|----------------------------------|-------------------------------------|-----------------------|\n",
    "| Feature Importance | Uses model-specific metrics (e.g., Gini impurity, information gain) to rank feature importance. | High                     | High                     | Low                              | Low                                 | High                  |\n",
    "\n",
    "### Feature Selection Methods Comparison\n",
    "\n",
    "| Method                          | Description                                                                                     | Evaluation Approach                | Feature Interactions         | Computational Cost         | Flexibility                                  | Use Case                                                      |\n",
    "|----------------------------------|-------------------------------------------------------------------------------------------------|------------------------------------|-----------------------------|----------------------------|-----------------------------------------------|---------------------------------------------------------------|\n",
    "| Feature Importance Threshold     | Selects features above a set importance threshold.                                              | Static (single evaluation)         | Ignores                     | Low                        | Relies on fixed threshold                     | Fast, simple screening                                       |\n",
    "| RFE (Recursive Feature Elimination) | Iteratively removes least important features, retraining the model each time.                 | Iterative (multiple retrainings)   | Considers dynamically       | High                       | Can specify number of features                | When feature interactions matter                              |\n",
    "| RFECV                            | RFE with cross-validation to find optimal feature set.                                         | Iterative + Cross-validation       | Considers dynamically       | Very High                   | Automatically determines optimal features     | Automated optimal selection                                   |\n",
    "\n",
    "*Tip: Use Table 1 to decide if feature importance is relevant for your model, then Table 2 to select the best feature selection method for your workflow.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Model Assumptions üå≤\n",
    "\n",
    "After developing your random forest model, consider the following best practices and checks:\n",
    "\n",
    "**1. Sufficient Sample Size**\n",
    "- Adequate data to create meaningful splits across multiple trees\n",
    "- *Ensure sufficient observations per terminal node across the forest*\n",
    "\n",
    "**2. Feature Relevance**\n",
    "- Important features are included; irrelevant features may dilute performance\n",
    "- *Review feature importance scores and remove low-impact features*\n",
    "\n",
    "**3. Check for Overfitting**\n",
    "- Model may memorize training patterns despite ensemble averaging\n",
    "- *Use out-of-bag (OOB) error, cross-validation, or limit n_estimators, max_depth, min_samples_split*\n",
    "\n",
    "**4. Handle Class Imbalance (Classification)**\n",
    "- Severe imbalance can bias predictions toward majority class\n",
    "- *Use class_weight='balanced', balanced_subsample, or SMOTE*\n",
    "\n",
    "**5. No Multicollinearity Requirement**\n",
    "- Random forests handle correlated features naturally through random feature selection\n",
    "- *Note: Correlated features may affect feature importance interpretation*\n",
    "\n",
    "**6. Interpretability Considerations**\n",
    "- Feature importance may favor high-cardinality or continuous variables\n",
    "- *Review importance scores critically, validate with domain knowledge, and consider permutation importance*\n",
    "\n",
    "**7. Hyperparameter Tuning**\n",
    "- Model performance depends on proper parameter selection\n",
    "- *Use GridSearchCV or RandomizedSearchCV for n_estimators, max_depth, min_samples_split, min_samples_leaf, max_features*\n",
    "\n",
    "**8. Validation Strategy**\n",
    "- Always evaluate on holdout/test set to assess generalization\n",
    "- *Check for data leakage and ensure train/test split is representative*\n",
    "\n",
    "**Advantages of Random Forests:**\n",
    "- No distributional assumptions (normality, homoscedasticity not required)\n",
    "- Robust to outliers due to ensemble averaging and threshold-based splits\n",
    "- Handles missing values (some implementations)\n",
    "- Captures non-linear relationships and feature interactions automatically\n",
    "- Reduces overfitting compared to single decision trees\n",
    "\n",
    "*Tip: Document any assumption violations and mitigation steps for transparency and reproducibility.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate SHAP (SHapley Additive exPlanations**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ***End of Construct Section Insights***\n",
    "- What model(s) performed best and why?\n",
    "    - *To be filled after model evaluation in Task 4b and 4c.*\n",
    "- Were any assumptions violated? How did you address them?\n",
    "    - *To be filled after checking model assumptions in Task 4b and 4c.*\n",
    "- What is your plan for communicating and deploying results?\n",
    "    - *To be filled after completing Task 5.\n",
    "- How will you evaluate model performance in production or real-world use?\n",
    "    - *To be filled after completing Task 5.*\n",
    "- What are the key limitations or risks of your model(s) that stakeholders should know?\n",
    "    - *To be filled after completing Task 5.*\n",
    "- What steps will you take to monitor, maintain, or update the model after deployment?\n",
    "    - *To be filled after completing Task 5.*\n",
    "- How will you ensure ethical and responsible use of your model(s)?\n",
    "    - *To be filled after completing Task 5.*\n",
    "- What metrics or visualizations will best communicate results to different audiences?\n",
    "    - *To be filled after completing Task 5.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Save Model Artifacts**\n",
    "\n",
    "**Checkpoint:** Save your champion model and any supporting artifacts for deployment or future reference.\n",
    "\n",
    "**Recommended to save:**\n",
    "- Trained model file (`.pkl`, `.joblib`, or framework-specific format)\n",
    "- Feature names and order used for training\n",
    "- Preprocessing transformers (scalers, encoders)\n",
    "- Model performance metrics\n",
    "- Feature importance scores\n",
    "- Training configuration and hyperparameters\n",
    "\n",
    "**Example naming:** `{project_name}_champion_model_{model_type}_{date}.pkl`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Task 4c. Model Comparison & Selection** \n",
    "\n",
    "**Compare All Models:**\n",
    "- Evaluate all developed models on the same test set\n",
    "- Compare performance metrics side-by-side\n",
    "- Consider both predictive performance and business requirements\n",
    "- Assess model complexity vs. interpretability trade-offs\n",
    "\n",
    "**Select Champion Model:**\n",
    "- Choose the model that best balances performance, interpretability, and business needs\n",
    "- Document the rationale for your selection\n",
    "- Identify backup models if primary choice faces deployment challenges\n",
    "\n",
    "**Recommended Comparison Table:**\n",
    "\n",
    "| Model               | Accuracy | Precision | Recall | F1-Score | AUC-ROC | Training Time | Interpretability | Notes |\n",
    "|---------------------|----------|-----------|--------|----------|---------|---------------|------------------|-------|\n",
    "| Logistic Regression |          |           |        |          |         |               | High             |       |\n",
    "| Decision Tree       |          |           |        |          |         |               | High             |       |\n",
    "| Random Forest       |          |           |        |          |         |               | Medium           |       |\n",
    "| XGBoost             |          |           |        |          |         |               | Medium           |       |\n",
    "\n",
    "**For Regression Models:**\n",
    "\n",
    "| Model               | RMSE | MAE | R¬≤ | Adjusted R¬≤ | Training Time | Interpretability | Notes |\n",
    "|---------------------|------|-----|----|-----------|--------------|--------------------|-------|\n",
    "| Linear Regression   |      |     |    |           |              | High               |       |\n",
    "| Decision Tree       |      |     |    |           |              | High               |       |\n",
    "| Random Forest       |      |     |    |           |              | Medium             |       |\n",
    "| XGBoost             |      |     |    |           |              | Medium             |       |\n",
    "\n",
    "**Champion Model Selection:**\n",
    "- **Selected Model:** [Model Name]\n",
    "- **Rationale:** [Why this model was chosen - consider performance, business needs, interpretability, deployment constraints]\n",
    "- **Key Strengths:** [What makes this model suitable]\n",
    "- **Limitations:** [Known weaknesses or constraints]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **Transition to Execute**\n",
    "\n",
    "With your model(s) developed and validated, focus on evaluating results, drawing insights, and making actionable recommendations.\n",
    "\n",
    "**‚úÖ Before proceeding, ensure you have:**\n",
    "- ‚úì Built and trained multiple models\n",
    "- ‚úì Validated model assumptions for each model type\n",
    "- ‚úì Compared models using consistent metrics\n",
    "- ‚úì Selected a champion model with documented rationale\n",
    "- ‚úì Saved model artifacts and configuration\n",
    "- ‚úì Assessed model limitations and potential risks\n",
    "\n",
    "**üìã Deliverables from Construct stage:**\n",
    "- Trained models with performance metrics\n",
    "- Model comparison table\n",
    "- Champion model selection and justification\n",
    "- Feature importance analysis\n",
    "- Model assumptions validation results\n",
    "- Saved model files and preprocessing artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Execute.png\" width=\"75\" height=\"75\" align=left>\n",
    "\n",
    "## **pacE: Execute**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Questions to reflect on during the Execute stage** üí≠\n",
    "\n",
    "- What are the key findings and practical implications from your statistical tests and predictive models?\n",
    "- How do your results align with business objectives, and what actionable recommendations emerge?\n",
    "- How confident are you in your conclusions, and what are the main limitations or risks?\n",
    "- How will you communicate results and significance to stakeholders, and what visualizations best support your message?\n",
    "- What is your plan for implementation, monitoring, and addressing ethical considerations or uncertainty?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task 5. Results and Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Task 5a. Statistical Results Summary**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Task 5b. Model Results Summary**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Task 5c. Model Testing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Task 5d. Business Impact Analysis**\n",
    "\n",
    "- **Key Findings & Significance:**  \n",
    "  [Summarize what statistical tests and models reveal about the business problem. Is the difference/prediction meaningful in real-world terms?]\n",
    "\n",
    "- **Business Context & Impact:**  \n",
    "  [How do findings affect operations, strategy, and stakeholders? Who is impacted and how?]\n",
    "\n",
    "- **Economic Assessment:**  \n",
    "  [Compare current state costs vs. implementation costs. What are the expected benefits and net value? When will benefits be realized?]\n",
    "\n",
    "- **Risks & Mitigation:**  \n",
    "  [What could go wrong? What are the risks of acting or not acting? How will risks be mitigated? What are the key success factors?]\n",
    "\n",
    "- **Action Plan & Monitoring:**  \n",
    "  [What actions are recommended? How will you measure success and monitor impact over time?]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Task 5e. Communication Materials**\n",
    "\n",
    "- **Key Messages:**  \n",
    "  - Primary Finding: [One-sentence summary of most important insight]  \n",
    "  - Business Relevance: [Why this matters to the organization]  \n",
    "  - Confidence Level: [Certainty of results]  \n",
    "  - Call to Action: [Recommended next steps]\n",
    "\n",
    "- **Stakeholder Summaries:**  \n",
    "  - Leadership: [Strategic impact, ROI, timeline, decisions]  \n",
    "  - Management: [Operational changes, resources, implementation steps]  \n",
    "  - Technical: [Methodology, limitations, technical requirements]\n",
    "\n",
    "- **Supporting Materials:**  \n",
    "  - Visualizations: [Charts/graphics to communicate findings]  \n",
    "  - Evidence: [Key statistics/metrics]  \n",
    "  - Risk Assessment: [Major concerns and mitigation]\n",
    "\n",
    "- **Implementation & Monitoring:**  \n",
    "  - Immediate Actions: [Quick wins, urgent steps]  \n",
    "  - Short-term Actions: [Milestones, next 1-3 months]  \n",
    "  - Long-term: [Strategic initiatives, >3 months]  \n",
    "  - Success Metrics: [How to measure effectiveness]  \n",
    "  - Monitoring: [Review schedule, feedback process]  \n",
    "  - Resources: [People, budget, technology]  \n",
    "  - Risk Mitigation: [Contingency plans]  \n",
    "  - Roles: [Who is responsible for each action]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
